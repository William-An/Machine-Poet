{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/william/anaconda3/envs/machine-poet/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words to Vector Representation\n",
    "embedding_feature_columns = hub.text_embedding_column(key = \"sentence\", module_spec = \"https://tfhub.dev/google/Wiki-words-500-with-normalization/1\", trainable=False)\n",
    "# emb = hub.Module(\"https://tfhub.dev/google/Wiki-words-500-with-normalization/1\")\n",
    "\n",
    "# NNML By Google\n",
    "# URL = https://tfhub.dev/google/nnlm-en-dim50/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def dataset_input_fn():\n",
    "    #def _parsefn(sentence):   \n",
    "    filenames = [\"poems/shakespeare/sonnets.txt\"]\n",
    "    # TODO Use skip and filter methods to preprocess data rather than manually do it\n",
    "    # TODO Use Dataset.map method to map '\\n' to 'xxxnewlinexxx'\n",
    "    dataset = tf.data.TextLineDataset(filenames)\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "    #dataset = dataset.batch(4)\n",
    "    dataset = dataset.repeat()\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    next_poem = iterator.get_next()\n",
    "    return {\"sentence\":next_poem}\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess.run(emb([dataset_input_fn()[\"words\"]]))\n",
    "with tf.Graph().as_default():\n",
    "    embed = hub.Module(\"https://tfhub.dev/google/nnlm-en-dim50/1\")\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        print(sess.run(embed([\" \"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess.run(emb([dataset_input_fn()[\"words\"]]))\n",
    "with tf.Graph().as_default():\n",
    "    embed = hub.Module(\"https://tfhub.dev/google/nnlm-en-dim128-with-normalization/1\")\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "        print(sess.run(tf.string_split(dataset_input_fn()[\"sentence\"])))\n",
    "        # print(sess.run(embed([dataset_input_fn()[\"sentence\"]])))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words to Vector Representation\n",
    "embedding_feature_columns = hub.text_embedding_column(key = \"sentence\", module_spec = \"https://tfhub.dev/google/nnlm-en-dim50/1\", trainable=False)\n",
    "# emb = hub.Module(\"https://tfhub.dev/google/Wiki-words-500-with-normalization/1\")\n",
    "\n",
    "# NNML By Google\n",
    "# URL = https://tfhub.dev/google/nnlm-en-dim50/1\n",
    "def dataset_input_fn():\n",
    "    def _insertSpace(sentence):\n",
    "        sentence = sentence.decode()\n",
    "        sentence = sentence.lower()\n",
    "        sentence = re.sub(r'([\\W\\d])', r' \\1 ', sentence)\n",
    "        return sentence\n",
    "    # Use tf.string_split if want to split string\n",
    "    # def _split(sentence):\n",
    "    #    return sentence.split()\n",
    "    def _getLabel(sentence):\n",
    "        splited = tf.string_split(sentence).values\n",
    "        ids = table.lookup(splited)\n",
    "        return {\"sentence\":sentence}, ids\n",
    "    filenames = [\"poems/shakespeare/sonnets.txt\"]\n",
    "    # TODO Use skip and filter methods to preprocess data rather than manually do it\n",
    "    # TODO Use Dataset.map method to map '\\n' to 'xxxnewlinexxx'\n",
    "    dataset = tf.data.TextLineDataset(filenames)\n",
    "    dataset = dataset.map(lambda sentence: tf.py_func(_insertSpace, [sentence], tf.string))\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "    dataset = dataset.batch(4)\n",
    "    dataset = dataset.map(_getLabel)\n",
    "    dataset = dataset.repeat()\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    next_poem = iterator.get_next()\n",
    "    return next_poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_fn(features, labels, params):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string2idtable = tf.contrib.lookup.index_table_from_file(vocabulary_file=\"vocabulary-shakespeare.txt\", num_oov_buckets=0)\n",
    "ids = table.lookup(tf.constant([\"!\", \"lake\", \"and\", \"palmer\"]))\n",
    "id2stringtabel = tf.contrib.lookup.index_to_string_table_from_file(vocabulary_file=\"vocabulary-shakespeare.txt\")\n",
    "string = id2stringtabel.lookup(tf.constant([1, 3, 5, 2365], dtype=tf.int64))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "tf.tables_initializer().run(session=sess)\n",
    "print(ids.eval(session=sess))\n",
    "print(string.eval(session=sess))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _insertSpace(sentence):\n",
    "    sentence = sentence.decode()\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r'([\\W\\d])', r' \\1 ', sentence)\n",
    "    return sentence\n",
    "# Use tf.string_split if want to split string\n",
    "# def _split(sentence):\n",
    "#    return sentence.split()\n",
    "def _getLabel(sentence):\n",
    "    splited = tf.string_split([sentence]).values\n",
    "    sentence = splited\n",
    "    # Use \" \" as x_0\n",
    "    sentence = tf.concat([tf.constant([\" \"], dtype=tf.string), sentence[0:-1]], 0)\n",
    "    ids = string2idtable.lookup(splited)\n",
    "    return {\"sentence\":sentence}, ids\n",
    "filenames = [\"poems/shakespeare/sonnets.txt\"]\n",
    "# TODO Use skip and filter methods to preprocess data rather than manually do it\n",
    "# TODO Use Dataset.map method to map '\\n' to 'xxxnewlinexxx'\n",
    "dataset = tf.data.TextLineDataset(filenames)\n",
    "dataset = dataset.map(lambda sentence: tf.py_func(_insertSpace, [sentence], tf.string))\n",
    "dataset = dataset.map(_getLabel)\n",
    "# dataset = dataset.shuffle(buffer_size=10000)\n",
    "# dataset = dataset.batch(4)\n",
    "\n",
    "dataset = dataset.repeat()\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_poem = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /var/folders/qz/dx3zfgtj2lqf70kv8b90s8wr0000gp/T/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Initialize variable module/embeddings/part_0:0 from checkpoint b'/var/folders/qz/dx3zfgtj2lqf70kv8b90s8wr0000gp/T/tfhub_modules/7f07056e3a4c9f125d5bd920ef3883605d8556a8/variables/variables' with embeddings\n",
      "(151, 50)\n",
      "(151, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 10.8991\n",
      "(162, 50)\n",
      "(162, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 12.9606\n",
      "(150, 50)\n",
      "(150, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 12.0228\n",
      "(142, 50)\n",
      "(142, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 11.6534\n",
      "(148, 50)\n",
      "(148, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 11.0056\n",
      "(160, 50)\n",
      "(160, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 11.3768\n",
      "(143, 50)\n",
      "(143, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 11.2140\n",
      "(158, 50)\n",
      "(158, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 10.7717\n",
      "(158, 50)\n",
      "(158, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 11.2527\n",
      "(163, 50)\n",
      "(163, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 10.9989\n",
      "(165, 50)\n",
      "(165, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 10.8647\n",
      "(153, 50)\n",
      "(153, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 10.4897\n",
      "(150, 50)\n",
      "(150, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 10.9280\n",
      "(151, 50)\n",
      "(151, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 11.0507\n",
      "(139, 50)\n",
      "(139, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 10.4988\n",
      "(144, 50)\n",
      "(144, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 10.2823\n",
      "(173, 50)\n",
      "(173, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 10.4152\n",
      "(161, 50)\n",
      "(161, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 10.4370\n",
      "(164, 50)\n",
      "(164, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 10.6555\n",
      "(169, 50)\n",
      "(169, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 10.8468\n",
      "(165, 50)\n",
      "(165, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 10.6050\n",
      "(159, 50)\n",
      "(159, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 9.9874\n",
      "(161, 50)\n",
      "(161, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 10.3634\n",
      "(165, 50)\n",
      "(165, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 10.2357\n",
      "(148, 50)\n",
      "(148, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 10.1970\n",
      "(154, 50)\n",
      "(154, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 9.9809\n",
      "(158, 50)\n",
      "(158, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 10.0734\n",
      "(165, 50)\n",
      "(165, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 10.2073\n",
      "(162, 50)\n",
      "(162, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 10.1617\n",
      "(160, 50)\n",
      "(160, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 249ms/step - loss: 9.9449\n",
      "(156, 50)\n",
      "(156, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 9.8754\n",
      "(157, 50)\n",
      "(157, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 9.9791\n",
      "(142, 50)\n",
      "(142, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 9.8550\n",
      "(159, 50)\n",
      "(159, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 9.9365\n",
      "(144, 50)\n",
      "(144, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 10.1880\n",
      "(148, 50)\n",
      "(148, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 9.8668\n",
      "(160, 50)\n",
      "(160, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 9.5199\n",
      "(148, 50)\n",
      "(148, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 9.6555\n",
      "(153, 50)\n",
      "(153, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 9.5726\n",
      "(166, 50)\n",
      "(166, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 9.0844\n",
      "(149, 50)\n",
      "(149, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 9.5337\n",
      "(170, 50)\n",
      "(170, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 8.7654\n",
      "(155, 50)\n",
      "(155, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 13.2290\n",
      "(154, 50)\n",
      "(154, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 13.3171\n",
      "(153, 50)\n",
      "(153, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 13.6046\n",
      "(160, 50)\n",
      "(160, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 13.0883\n",
      "(166, 50)\n",
      "(166, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 13.8761\n",
      "(153, 50)\n",
      "(153, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 13.9089\n",
      "(150, 50)\n",
      "(150, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 13.7299\n",
      "(156, 50)\n",
      "(156, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 13.3255\n",
      "(169, 50)\n",
      "(169, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 13.7497\n",
      "(148, 50)\n",
      "(148, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 13.5558\n",
      "(144, 50)\n",
      "(144, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 13.9882\n",
      "(150, 50)\n",
      "(150, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 13.3458\n",
      "(144, 50)\n",
      "(144, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 13.2766\n",
      "(160, 50)\n",
      "(160, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 13.5604\n",
      "(158, 50)\n",
      "(158, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 14.0294\n",
      "(150, 50)\n",
      "(150, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 13.9579\n",
      "(145, 50)\n",
      "(145, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 13.2316\n",
      "(146, 50)\n",
      "(146, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 13.2187\n",
      "(156, 50)\n",
      "(156, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 13.7578\n",
      "(150, 50)\n",
      "(150, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 14.2208\n",
      "(159, 50)\n",
      "(159, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 13.2290\n",
      "(150, 50)\n",
      "(150, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 13.3462\n",
      "(156, 50)\n",
      "(156, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 13.0978\n",
      "(138, 50)\n",
      "(138, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 12.7845\n",
      "(141, 50)\n",
      "(141, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 13.2311\n",
      "(142, 50)\n",
      "(142, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 13.4583\n",
      "(165, 50)\n",
      "(165, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 12.9675\n",
      "(157, 50)\n",
      "(157, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 12.9305\n",
      "(154, 50)\n",
      "(154, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 13.6391\n",
      "(151, 50)\n",
      "(151, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 14.2047\n",
      "(170, 50)\n",
      "(170, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 13.5378\n",
      "(148, 50)\n",
      "(148, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 13.5875\n",
      "(153, 50)\n",
      "(153, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 13.2521\n",
      "(147, 50)\n",
      "(147, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 13.4638\n",
      "(145, 50)\n",
      "(145, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 11.9441\n",
      "(140, 50)\n",
      "(140, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 12.8477\n",
      "(151, 50)\n",
      "(151, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 13.2947\n",
      "(160, 50)\n",
      "(160, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 12.8309\n",
      "(160, 50)\n",
      "(160, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 12.5705\n",
      "(148, 50)\n",
      "(148, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 12.1678\n",
      "(149, 50)\n",
      "(149, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 11.4896\n",
      "(148, 50)\n",
      "(148, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 10.9646\n",
      "(160, 50)\n",
      "(160, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 10.7924\n",
      "(145, 50)\n",
      "(145, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 10.4638\n",
      "(159, 50)\n",
      "(159, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 9.8256\n",
      "(154, 50)\n",
      "(154, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 10.2177\n",
      "(152, 50)\n",
      "(152, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 10.0290\n",
      "(171, 50)\n",
      "(171, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 9.6712\n",
      "(155, 50)\n",
      "(155, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 9.6747\n",
      "(154, 50)\n",
      "(154, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 9.6299\n",
      "(162, 50)\n",
      "(162, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 9.1280\n",
      "(148, 50)\n",
      "(148, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 9.4297\n",
      "(150, 50)\n",
      "(150, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 8.9757\n",
      "(159, 50)\n",
      "(159, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 9.2127\n",
      "(156, 50)\n",
      "(156, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 9.2929\n",
      "(164, 50)\n",
      "(164, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 8.8007\n",
      "(175, 50)\n",
      "(175, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 8.9307\n",
      "(152, 50)\n",
      "(152, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 8.9727\n",
      "(161, 50)\n",
      "(161, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 8.7116\n",
      "(157, 50)\n",
      "(157, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 8.6265\n",
      "(154, 50)\n",
      "(154, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 8.5287\n",
      "(169, 50)\n",
      "(169, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 8.3297\n",
      "(162, 50)\n",
      "(162, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 8.4107\n",
      "(147, 50)\n",
      "(147, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 7.9578\n",
      "(155, 50)\n",
      "(155, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 8.4488\n",
      "(163, 50)\n",
      "(163, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 7.4044\n",
      "(159, 50)\n",
      "(159, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 6.9279\n",
      "(164, 50)\n",
      "(164, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 5.8521\n",
      "(152, 50)\n",
      "(152, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 14.0832\n",
      "(158, 50)\n",
      "(158, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 14.9172\n",
      "(155, 50)\n",
      "(155, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 14.7043\n",
      "(156, 50)\n",
      "(156, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 14.5209\n",
      "(159, 50)\n",
      "(159, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 14.4676\n",
      "(154, 50)\n",
      "(154, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 14.3165\n",
      "(144, 50)\n",
      "(144, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 14.4359\n",
      "(157, 50)\n",
      "(157, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 14.3480\n",
      "(152, 50)\n",
      "(152, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 14.5171\n",
      "(164, 50)\n",
      "(164, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 14.3028\n",
      "(152, 50)\n",
      "(152, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 14.4990\n",
      "(141, 50)\n",
      "(141, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 14.7794\n",
      "(145, 50)\n",
      "(145, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 14.4270\n",
      "(157, 50)\n",
      "(157, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 14.0209\n",
      "(145, 50)\n",
      "(145, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 14.0010\n",
      "(136, 50)\n",
      "(136, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 14.2376\n",
      "(159, 50)\n",
      "(159, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 14.7112\n",
      "(150, 50)\n",
      "(150, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 13.9970\n",
      "(166, 50)\n",
      "(166, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 13.8189\n",
      "(162, 50)\n",
      "(162, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 14.3322\n",
      "(158, 50)\n",
      "(158, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 14.6190\n",
      "(143, 50)\n",
      "(143, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 13.9667\n",
      "(171, 50)\n",
      "(171, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 14.4067\n",
      "(167, 50)\n",
      "(167, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 14.3524\n",
      "(170, 50)\n",
      "(170, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 14.6561\n",
      "(175, 50)\n",
      "(175, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 14.6833\n",
      "(170, 50)\n",
      "(170, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 14.5726\n",
      "(158, 50)\n",
      "(158, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 14.0715\n",
      "(164, 50)\n",
      "(164, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 14.3126\n",
      "(164, 50)\n",
      "(164, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 14.4282\n",
      "(156, 50)\n",
      "(156, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 14.0180\n",
      "(163, 50)\n",
      "(163, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 14.1277\n",
      "(159, 50)\n",
      "(159, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 13.6123\n",
      "(153, 50)\n",
      "(153, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 14.0546\n",
      "(144, 50)\n",
      "(144, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 14.1821\n",
      "(154, 50)\n",
      "(154, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 13.6523\n",
      "(146, 50)\n",
      "(146, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 13.7707\n",
      "(170, 50)\n",
      "(170, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 14.5977\n",
      "(163, 50)\n",
      "(163, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 14.6031\n",
      "(153, 50)\n",
      "(153, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 14.3143\n",
      "(156, 50)\n",
      "(156, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 14.1870\n",
      "(170, 50)\n",
      "(170, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 14.0313\n",
      "(157, 50)\n",
      "(157, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 13.7384\n",
      "(155, 50)\n",
      "(155, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 225ms/step - loss: 13.7084\n",
      "(151, 50)\n",
      "(151, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 14.1612\n",
      "(162, 50)\n",
      "(162, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 14.3686\n",
      "(150, 50)\n",
      "(150, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 14.1961\n",
      "(142, 50)\n",
      "(142, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 14.2232\n",
      "(148, 50)\n",
      "(148, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 14.0175\n",
      "(160, 50)\n",
      "(160, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 14.0676\n",
      "(143, 50)\n",
      "(143, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 13.5581\n",
      "(158, 50)\n",
      "(158, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 13.4768\n",
      "(158, 50)\n",
      "(158, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 14.0964\n",
      "(163, 50)\n",
      "(163, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 14.0555\n",
      "(165, 50)\n",
      "(165, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 13.3622\n",
      "(153, 50)\n",
      "(153, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 13.6585\n",
      "(150, 50)\n",
      "(150, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 14.1931\n",
      "(151, 50)\n",
      "(151, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 13.9227\n",
      "(139, 50)\n",
      "(139, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 13.6565\n",
      "(144, 50)\n",
      "(144, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 14.1292\n",
      "(173, 50)\n",
      "(173, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 14.2090\n",
      "(161, 50)\n",
      "(161, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 266ms/step - loss: 14.0503\n",
      "(164, 50)\n",
      "(164, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 13.9262\n",
      "(169, 50)\n",
      "(169, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 273ms/step - loss: 13.9227\n",
      "(165, 50)\n",
      "(165, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 14.2617\n",
      "(159, 50)\n",
      "(159, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 14.4700\n",
      "(161, 50)\n",
      "(161, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 14.1930\n",
      "(165, 50)\n",
      "(165, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 14.3714\n",
      "(148, 50)\n",
      "(148, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 13.6399\n",
      "(154, 50)\n",
      "(154, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 13.8118\n",
      "(158, 50)\n",
      "(158, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 258ms/step - loss: 13.6949\n",
      "(165, 50)\n",
      "(165, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 13.5482\n",
      "(162, 50)\n",
      "(162, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 13.5095\n",
      "(160, 50)\n",
      "(160, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 13.1867\n",
      "(156, 50)\n",
      "(156, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 13.5176\n",
      "(157, 50)\n",
      "(157, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 13.3121\n",
      "(142, 50)\n",
      "(142, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 12.6477\n",
      "(159, 50)\n",
      "(159, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 12.7561\n",
      "(144, 50)\n",
      "(144, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 12.4271\n",
      "(148, 50)\n",
      "(148, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 12.4766\n",
      "(160, 50)\n",
      "(160, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 12.8360\n",
      "(148, 50)\n",
      "(148, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 12.2988\n",
      "(153, 50)\n",
      "(153, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 11.8174\n",
      "(166, 50)\n",
      "(166, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 11.5778\n",
      "(149, 50)\n",
      "(149, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 11.6978\n",
      "(170, 50)\n",
      "(170, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 10.5511\n",
      "(155, 50)\n",
      "(155, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 11.5854\n",
      "(154, 50)\n",
      "(154, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 11.4864\n",
      "(153, 50)\n",
      "(153, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 11.5057\n",
      "(160, 50)\n",
      "(160, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 265ms/step - loss: 12.0593\n",
      "(166, 50)\n",
      "(166, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 10.8937\n",
      "(153, 50)\n",
      "(153, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 11.1118\n",
      "(150, 50)\n",
      "(150, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 11.0786\n",
      "(156, 50)\n",
      "(156, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 11.5626\n",
      "(169, 50)\n",
      "(169, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 10.9862\n",
      "(148, 50)\n",
      "(148, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 11.8210\n",
      "(144, 50)\n",
      "(144, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 11.4229\n",
      "(150, 50)\n",
      "(150, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 11.5890\n",
      "(144, 50)\n",
      "(144, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 11.3827\n",
      "(160, 50)\n",
      "(160, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 10.8255\n",
      "(158, 50)\n",
      "(158, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 10.5941\n",
      "(150, 50)\n",
      "(150, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 10.9159\n",
      "(145, 50)\n",
      "(145, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 11.1306\n",
      "(146, 50)\n",
      "(146, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 10.8550\n",
      "(156, 50)\n",
      "(156, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 10.3413\n",
      "(150, 50)\n",
      "(150, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 222ms/step - loss: 9.3526\n",
      "(159, 50)\n",
      "(159, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 10.2762\n",
      "(150, 50)\n",
      "(150, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 9.6287\n",
      "(156, 50)\n",
      "(156, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 12.1587\n",
      "(138, 50)\n",
      "(138, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 11.9935\n",
      "(141, 50)\n",
      "(141, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 12.4166\n",
      "(142, 50)\n",
      "(142, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 12.6908\n",
      "(165, 50)\n",
      "(165, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 12.3733\n",
      "(157, 50)\n",
      "(157, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 12.1062\n",
      "(154, 50)\n",
      "(154, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 12.8391\n",
      "(151, 50)\n",
      "(151, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 13.5092\n",
      "(170, 50)\n",
      "(170, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 12.2623\n",
      "(148, 50)\n",
      "(148, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 12.6903\n",
      "(153, 50)\n",
      "(153, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 9.2903\n",
      "(147, 50)\n",
      "(147, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 235ms/step - loss: 9.1273\n",
      "(145, 50)\n",
      "(145, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 10.5595\n",
      "(140, 50)\n",
      "(140, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 280ms/step - loss: 8.9952\n",
      "(151, 50)\n",
      "(151, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 12.6602\n",
      "(160, 50)\n",
      "(160, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 272ms/step - loss: 13.0793\n",
      "(160, 50)\n",
      "(160, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 13.5152\n",
      "(148, 50)\n",
      "(148, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 12.5625\n",
      "(149, 50)\n",
      "(149, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 224ms/step - loss: 13.0327\n",
      "(148, 50)\n",
      "(148, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 278ms/step - loss: 12.8833\n",
      "(160, 50)\n",
      "(160, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 12.9970\n",
      "(145, 50)\n",
      "(145, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 12.7703\n",
      "(159, 50)\n",
      "(159, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 233ms/step - loss: 13.1926\n",
      "(154, 50)\n",
      "(154, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 13.3607\n",
      "(152, 50)\n",
      "(152, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 13.5187\n",
      "(171, 50)\n",
      "(171, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 13.5223\n",
      "(155, 50)\n",
      "(155, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 13.2615\n",
      "(154, 50)\n",
      "(154, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 13.7517\n",
      "(162, 50)\n",
      "(162, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 12.2774\n",
      "(148, 50)\n",
      "(148, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 12.6521\n",
      "(150, 50)\n",
      "(150, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 12.7930\n",
      "(159, 50)\n",
      "(159, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 13.3578\n",
      "(156, 50)\n",
      "(156, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 12.7571\n",
      "(164, 50)\n",
      "(164, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 12.9484\n",
      "(175, 50)\n",
      "(175, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 288ms/step - loss: 12.5699\n",
      "(152, 50)\n",
      "(152, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 12.3946\n",
      "(161, 50)\n",
      "(161, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 13.1545\n",
      "(157, 50)\n",
      "(157, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 12.8634\n",
      "(154, 50)\n",
      "(154, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 13.4897\n",
      "(169, 50)\n",
      "(169, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 11.8272\n",
      "(162, 50)\n",
      "(162, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 264ms/step - loss: 12.7844\n",
      "(147, 50)\n",
      "(147, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 12.8656\n",
      "(155, 50)\n",
      "(155, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 13.1036\n",
      "(163, 50)\n",
      "(163, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 292ms/step - loss: 12.4969\n",
      "(159, 50)\n",
      "(159, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 260ms/step - loss: 13.5339\n",
      "(164, 50)\n",
      "(164, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 13.1201\n",
      "(152, 50)\n",
      "(152, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 13.3882\n",
      "(158, 50)\n",
      "(158, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 13.0701\n",
      "(155, 50)\n",
      "(155, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 13.3630\n",
      "(156, 50)\n",
      "(156, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 12.4355\n",
      "(159, 50)\n",
      "(159, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 9.1044\n",
      "(154, 50)\n",
      "(154, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 261ms/step - loss: 9.3044\n",
      "(144, 50)\n",
      "(144, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 231ms/step - loss: 9.9799\n",
      "(157, 50)\n",
      "(157, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 10.0326\n",
      "(152, 50)\n",
      "(152, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 9.5307\n",
      "(164, 50)\n",
      "(164, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 9.6059\n",
      "(152, 50)\n",
      "(152, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 9.4790\n",
      "(141, 50)\n",
      "(141, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 9.8937\n",
      "(145, 50)\n",
      "(145, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 9.6806\n",
      "(157, 50)\n",
      "(157, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 9.7198\n",
      "(145, 50)\n",
      "(145, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 9.3833\n",
      "(136, 50)\n",
      "(136, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 10.0515\n",
      "(159, 50)\n",
      "(159, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 251ms/step - loss: 10.0600\n",
      "(150, 50)\n",
      "(150, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 10.0943\n",
      "(166, 50)\n",
      "(166, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 8.9672\n",
      "(162, 50)\n",
      "(162, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 9.3281\n",
      "(158, 50)\n",
      "(158, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 9.7653\n",
      "(143, 50)\n",
      "(143, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 9.4190\n",
      "(171, 50)\n",
      "(171, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 263ms/step - loss: 9.3151\n",
      "(167, 50)\n",
      "(167, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 9.0285\n",
      "(170, 50)\n",
      "(170, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 9.2978\n",
      "(175, 50)\n",
      "(175, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 12.8884\n",
      "(170, 50)\n",
      "(170, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 13.6322\n",
      "(158, 50)\n",
      "(158, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 240ms/step - loss: 13.0490\n",
      "(164, 50)\n",
      "(164, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 13.1949\n",
      "(164, 50)\n",
      "(164, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 13.6844\n",
      "(156, 50)\n",
      "(156, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 12.9951\n",
      "(163, 50)\n",
      "(163, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 13.4488\n",
      "(159, 50)\n",
      "(159, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 13.2063\n",
      "(153, 50)\n",
      "(153, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 13.6555\n",
      "(144, 50)\n",
      "(144, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 12.3343\n",
      "(154, 50)\n",
      "(154, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 257ms/step - loss: 12.6684\n",
      "(146, 50)\n",
      "(146, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 244ms/step - loss: 13.4040\n",
      "(170, 50)\n",
      "(170, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 13.6860\n",
      "(163, 50)\n",
      "(163, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 267ms/step - loss: 13.4073\n",
      "(153, 50)\n",
      "(153, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 13.7726\n",
      "(156, 50)\n",
      "(156, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 13.1636\n",
      "(170, 50)\n",
      "(170, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 255ms/step - loss: 13.2969\n",
      "(157, 50)\n",
      "(157, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 239ms/step - loss: 12.7583\n",
      "(155, 50)\n",
      "(155, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 11.9797\n",
      "(151, 50)\n",
      "(151, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 11.1483\n",
      "(162, 50)\n",
      "(162, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 256ms/step - loss: 13.1243\n",
      "(150, 50)\n",
      "(150, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 13.8639\n",
      "(142, 50)\n",
      "(142, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 13.7186\n",
      "(148, 50)\n",
      "(148, 11405)\n",
      "Epoch 1/1\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 13.7866\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e2ee234a4490>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sentence\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11405\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/machine-poet/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/machine-poet/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/machine-poet/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/machine-poet/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/machine-poet/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1307\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m~/anaconda3/envs/machine-poet/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1338\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default():\n",
    "    embed = hub.Module(\"https://tfhub.dev/google/nnlm-en-dim50/1\")\n",
    "    string2idtable = tf.contrib.lookup.index_table_from_file(vocabulary_file=\"vocabulary-shakespeare.txt\", num_oov_buckets=0)\n",
    "    id2stringtabel = tf.contrib.lookup.index_to_string_table_from_file(vocabulary_file=\"vocabulary-shakespeare.txt\")\n",
    "    def _insertSpace(sentence):\n",
    "        sentence = sentence.decode()\n",
    "        sentence = sentence.lower()\n",
    "        sentence = re.sub(r'([\\W\\d])', r' \\1 ', sentence)\n",
    "        return sentence\n",
    "    # Use tf.string_split if want to split string\n",
    "    # def _split(sentence):\n",
    "    #    return sentence.split()\n",
    "    def _getLabel(sentence):\n",
    "        splited = tf.string_split([sentence]).values\n",
    "        sentence = splited\n",
    "        # Use \" \" as x_0\n",
    "        sentence = tf.concat([tf.constant([\" \"], dtype=tf.string), sentence[0:-1]], 0)\n",
    "        ids = string2idtable.lookup(splited)\n",
    "        return {\"sentence\":sentence}, ids# {\"sentence\":sentence}, ids\n",
    "    filenames = [\"poems/shakespeare/sonnets.txt\"]\n",
    "    # TODO Use skip and filter methods to preprocess data rather than manually do it\n",
    "    # TODO Use Dataset.map method to map '\\n' to 'xxxnewlinexxx'\n",
    "    dataset = tf.data.TextLineDataset(filenames)\n",
    "    dataset = dataset.map(lambda sentence: tf.py_func(_insertSpace, [sentence], tf.string))\n",
    "    dataset = dataset.map(_getLabel)\n",
    "    # dataset = dataset.shuffle(buffer_size=10000)\n",
    "    # dataset = dataset.batch(4)\n",
    "    dataset = dataset.repeat()\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    next_poem = iterator.get_next()\n",
    "    \n",
    "    \n",
    "    \n",
    "    # TODO Model SHOULD BE A LANGUAGE MODEL\n",
    "    model = tf.keras.Sequential()\n",
    "    # TODO Masking / Padding\n",
    "    model.add(tf.keras.layers.Masking(mask_value=0., input_shape=(None, 50)))\n",
    "    model.add(tf.keras.layers.LSTM(128, return_sequences=True))\n",
    "    model.add(tf.keras.layers.Dense(11405))\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\")\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        tf.tables_initializer().run(session=sess)\n",
    "        sess.run(iterator.initializer)\n",
    "        for _ in range(1000):\n",
    "            poem = sess.run(next_poem)\n",
    "            x = poem[0][\"sentence\"]\n",
    "            y = poem[1]\n",
    "            x = sess.run(embed(x))\n",
    "            print(x.shape)\n",
    "            y = tf.keras.utils.to_categorical(y, 11405)\n",
    "            print(y.shape)\n",
    "            model.fit(x=np.array([x]), y=np.array([y]))\n",
    "#for _ in range(1):\n",
    "#    poem = sess.run(next_poem)\n",
    "#    print(type(poem[0][\"sentence\"]))\n",
    "#    print(type(poem[1]))\n",
    "# (lambda: next_poem)() # As input_fn? for Estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_1 (Masking)          (None, None, 50)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 128)         91648     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 11405)       1471245   \n",
      "=================================================================\n",
      "Total params: 1,562,893\n",
      "Trainable params: 1,562,893\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected masking_1_input to have 3 dimensions, but got array with shape (1, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-28f69171bf36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/machine-poet/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                        \u001b[0;34m'you should specify the `steps` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                        'argument.')\n\u001b[0;32m-> 1327\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/machine-poet/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m         exception_prefix='input')\n\u001b[0m\u001b[1;32m    766\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/machine-poet/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    181\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected masking_1_input to have 3 dimensions, but got array with shape (1, 1)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
